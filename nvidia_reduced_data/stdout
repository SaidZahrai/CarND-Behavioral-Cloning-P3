(/opt/carnd_p3/behavioral) root@ab70564d4946:/home/workspace/CarND-Behavioral-Cloning-P3/nvidia_reduced_dat
a# python ../model.py -m nnidia_reduced -d ../data
Using TensorFlow backend.
Training data will be taken from:  ../data
Output file is  model_nnidia_reduced  +.h5
Please confirm with "Y"!  :: Y
1 directory as input data found.
../data
No valid model requested.
python model.py -h
(/opt/carnd_p3/behavioral) root@ab70564d4946:/home/workspace/CarND-Behavioral-Cloning-P3/nvidia_reduced_dat
a# python ../model.py -m nvidia_reduced -d ../data
Using TensorFlow backend.
Training data will be taken from:  ../data
Output file is  model_nvidia_reduced  +.h5
Please confirm with "Y"!  :: Y
1 directory as input data found.
../data
No valid model requested.
python model.py -h
(/opt/carnd_p3/behavioral) root@ab70564d4946:/home/workspace/CarND-Behavioral-Cloning-P3/nvidia_reduced_dat
a# python ../model.py -m reduced_nvidia -d ../data
Using TensorFlow backend.
Training data will be taken from:  ../data
Output file is  model_reduced_nvidia  +.h5
Please confirm with "Y"!  :: Y
1 directory as input data found.
../data
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
cropping2d_1 (Cropping2D)    (None, 50, 280, 3)        0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 50, 280, 3)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 280, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 23, 138, 12)       912       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 10, 67, 18)        5418      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 63, 24)         10824     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 61, 32)         6944      
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 59, 32)         9248      
_________________________________________________________________
flatten_1 (Flatten)          (None, 3776)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 3776)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 50)                188850    
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 25)                1275      
_________________________________________________________________
batch_normalization_1 (Batch (None, 25)                100       
_________________________________________________________________
activation_2 (Activation)    (None, 25)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                260       
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
=================================================================
Total params: 223,842
Trainable params: 223,792
Non-trainable params: 50
_________________________________________________________________
Start training with data from directory:  ../data
Epoch 1/10
2019-08-10 23:25:44.718881: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-10 23:25:44.718956: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-10 23:25:44.718994: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-08-10 23:25:44.719028: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-10 23:25:44.719049: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2019-08-10 23:25:44.837419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-10 23:25:44.838551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.05GiB
2019-08-10 23:25:44.838606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2019-08-10 23:25:44.838668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2019-08-10 23:25:44.838717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
603/603 [==============================] - 89s 148ms/step - loss: 0.0550 - val_loss: 0.0215

Epoch 00001: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 2/10
603/603 [==============================] - 86s 143ms/step - loss: 0.0321 - val_loss: 0.0207

Epoch 00002: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 3/10
603/603 [==============================] - 87s 144ms/step - loss: 0.0279 - val_loss: 0.0208

Epoch 00003: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 4/10
603/603 [==============================] - 84s 140ms/step - loss: 0.0254 - val_loss: 0.0173

Epoch 00004: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 5/10
603/603 [==============================] - 87s 144ms/step - loss: 0.0238 - val_loss: 0.0185

Epoch 00005: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 6/10
603/603 [==============================] - 86s 143ms/step - loss: 0.0223 - val_loss: 0.0182

Epoch 00006: saving model to .//checkpoints-8-10-23-0001-01-01 00:00:00-43/model.ckpt
Epoch 00006: early stopping
dict_keys(['loss', 'val_loss'])

