 ../drive.py model_nvidia.h5 
Using TensorFlow backend.
Traceback (most recent call last):
  File "../drive.py", line 114, in <module>
    f = h5py.File(args.model, mode='r')
  File "/opt/carnd_p3/behavioral/lib/python3.5/site-packages/h5py/_hl/files.py", line 394, in __init__
    swmr=swmr)
  File "/opt/carnd_p3/behavioral/lib/python3.5/site-packages/h5py/_hl/files.py", line 170, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 85, in h5py.h5f.open
OSError: Unable to open file (unable to open file: name = 'model_nvidia.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
(/opt/carnd_p3/behavioral) root@165d09242b08:/home/workspace/CarND-Behavioral-Cloning-P3/lenet_data# python model.py -m lenet -d ../data
Using TensorFlow backend.
Training data will be taken from:  ../data
Output file is  model_lenet  +.h5
Please confirm with "Y"!  :: Y
1 directory as input data found.
../data
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
cropping2d_1 (Cropping2D)    (None, 50, 280, 3)        0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 50, 280, 3)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 280, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 48, 278, 6)        168       
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 24, 139, 6)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 137, 16)       880       
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 11, 68, 16)        0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 11968)             0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 11968)             0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 11968)             47872     
_________________________________________________________________
dense_1 (Dense)              (None, 120)               1436280   
_________________________________________________________________
dense_2 (Dense)              (None, 84)                10164     
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 85        
=================================================================
Total params: 1,495,449
Trainable params: 1,471,513
Non-trainable params: 23,936
_________________________________________________________________
Start training with data from directory:  ../data
Epoch 1/10
2019-08-06 20:53:00.649833: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-06 20:53:00.651116: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-06 20:53:00.651897: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2019-08-06 20:53:00.652888: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2019-08-06 20:53:00.653811: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2019-08-06 20:53:00.768363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-08-06 20:53:00.770500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:955] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:04.0
Total memory: 11.17GiB
Free memory: 11.05GiB
2019-08-06 20:53:00.771652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:976] DMA: 0 
2019-08-06 20:53:00.772006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:986] 0:   Y 
2019-08-06 20:53:00.772120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1045] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)
603/603 [==============================] - 94s 155ms/step - loss: 0.0634 - val_loss: 0.0196

Epoch 00001: saving model to .//checkpoints-8-6-20-0001-01-01 00:00:00-59/model.ckpt
Epoch 2/10
603/603 [==============================] - 88s 146ms/step - loss: 0.0258 - val_loss: 0.0156

Epoch 00002: saving model to .//checkpoints-8-6-20-0001-01-01 00:00:00-59/model.ckpt
Epoch 3/10
603/603 [==============================] - 88s 146ms/step - loss: 0.0230 - val_loss: 0.0146

Epoch 00003: saving model to .//checkpoints-8-6-20-0001-01-01 00:00:00-59/model.ckpt
Epoch 4/10
603/603 [==============================] - 88s 146ms/step - loss: 0.0215 - val_loss: 0.0154

Epoch 00004: saving model to .//checkpoints-8-6-20-0001-01-01 00:00:00-59/model.ckpt
Epoch 5/10
603/603 [==============================] - 88s 146ms/step - loss: 0.0202 - val_loss: 0.0162

Epoch 00005: saving model to .//checkpoints-8-6-20-0001-01-01 00:00:00-59/model.ckpt
Epoch 00005: early stopping
dict_keys(['val_loss', 'loss'])
