(carnd-term1) said:nvidia$ python ../model.py -m nvidia -d '../Data/*'
Using TensorFlow backend.
Training data will be taken from:  ../Data/*
Output file is  model_nvidia  +.h5
Please confirm with "Y"!  :: Y
3 directory as input data found.
../Data/data
../Data/custom2
../Data/custom1
WARNING: Logging before flag parsing goes to stderr.
W0804 01:15:33.530416 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0804 01:15:33.550741 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0804 01:15:33.561905 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

W0804 01:15:33.569290 139860280801088 deprecation.py:506] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0804 01:15:33.583507 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
cropping2d_1 (Cropping2D)    (None, 50, 280, 3)        0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 50, 280, 3)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 280, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 23, 138, 12)       912       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 10, 67, 18)        5418      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 63, 24)         10824     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 61, 32)         6944      
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 59, 32)         9248      
_________________________________________________________________
flatten_1 (Flatten)          (None, 3776)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 3776)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 50)                188850    
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 25)                1275      
_________________________________________________________________
batch_normalization_1 (Batch (None, 25)                100       
_________________________________________________________________
activation_2 (Activation)    (None, 25)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                260       
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
=================================================================
Total params: 223,842
Trainable params: 223,792
Non-trainable params: 50
_________________________________________________________________
Start training with data from directory:  ../Data/data
Start training with data from directory:  ../Data/custom2
Start training with data from directory:  ../Data/custom1
W0804 01:15:34.263098 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0804 01:15:34.598794 139860280801088 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

Epoch 1/10
2019-08-04 01:15:35.277861: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-04 01:15:35.306622: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2019-08-04 01:15:35.317537: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6eefcc0 executing computations on platform Host. Devices:
2019-08-04 01:15:35.317574: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-08-04 01:15:35.881168: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
  64/1148 [>.............................] - ETA: 3:22 - loss: 0.1484^CTraceback (most recent call last):
  File "../model.py", line 256, in <module>
    main(sys.argv[1:])
  File "../model.py", line 251, in main
    train_model(model,dataDir,outputfile)
  File "../model.py", line 197, in train_model
    callbacks=[cp_callback, es_callback])
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/legacy/interfaces.py", line 91, in wrapper
    return func(*args, **kwargs)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py", line 1418, in fit_generator
    initial_epoch=initial_epoch)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training_generator.py", line 217, in fit_generator
    class_weight=class_weight)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py", line 1217, in train_on_batch
    outputs = self.train_function(ins)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py", line 2715, in __call__
    return self._call(inputs)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py", line 2675, in _call
    fetched = self._callable_fn(*array_vals)
  File "/home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/tensorflow/python/client/session.py", line 1458, in __call__
    run_metadata_ptr)
KeyboardInterrupt
(carnd-term1) said:nvidia$ rm -r *
(carnd-term1) said:nvidia$ python ../model.py -m nvidia -d '../Data/*'
Using TensorFlow backend.
Training data will be taken from:  ../Data/*
Output file is  model_nvidia  +.h5
Please confirm with "Y"!  :: Y
3 directory as input data found.
../Data/data
../Data/custom2
../Data/custom1
WARNING: Logging before flag parsing goes to stderr.
W0804 01:16:42.067951 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0804 01:16:42.086503 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0804 01:16:42.099092 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.

W0804 01:16:42.106933 140576488945472 deprecation.py:506] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
W0804 01:16:42.122109 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
cropping2d_1 (Cropping2D)    (None, 50, 280, 3)        0         
_________________________________________________________________
lambda_1 (Lambda)            (None, 50, 280, 3)        0         
_________________________________________________________________
dropout_1 (Dropout)          (None, 50, 280, 3)        0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 23, 138, 12)       912       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 10, 67, 18)        5418      
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 6, 63, 24)         10824     
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 61, 32)         6944      
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 2, 59, 32)         9248      
_________________________________________________________________
flatten_1 (Flatten)          (None, 3776)              0         
_________________________________________________________________
dropout_2 (Dropout)          (None, 3776)              0         
_________________________________________________________________
dense_1 (Dense)              (None, 50)                188850    
_________________________________________________________________
activation_1 (Activation)    (None, 50)                0         
_________________________________________________________________
dropout_3 (Dropout)          (None, 50)                0         
_________________________________________________________________
dense_2 (Dense)              (None, 25)                1275      
_________________________________________________________________
batch_normalization_1 (Batch (None, 25)                100       
_________________________________________________________________
activation_2 (Activation)    (None, 25)                0         
_________________________________________________________________
dense_3 (Dense)              (None, 10)                260       
_________________________________________________________________
activation_3 (Activation)    (None, 10)                0         
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 11        
=================================================================
Total params: 223,842
Trainable params: 223,792
Non-trainable params: 50
_________________________________________________________________
Start training with data from directory:  ../Data/data
Start training with data from directory:  ../Data/custom2
Start training with data from directory:  ../Data/custom1
W0804 01:16:42.796308 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

W0804 01:16:43.158343 140576488945472 deprecation_wrapper.py:119] From /home/said/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.

Epoch 1/10
2019-08-04 01:16:43.854779: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-04 01:16:43.878657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
2019-08-04 01:16:43.878999: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x72a92b0 executing computations on platform Host. Devices:
2019-08-04 01:16:43.879020: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2019-08-04 01:16:44.405567: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
1144/1144 [==============================] - 192s 168ms/step - loss: 0.0419 - val_loss: 0.0188

Epoch 00001: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 2/10
1144/1144 [==============================] - 194s 170ms/step - loss: 0.0222 - val_loss: 0.0167

Epoch 00002: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 3/10
1144/1144 [==============================] - 209s 183ms/step - loss: 0.0205 - val_loss: 0.0160

Epoch 00003: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 4/10
1144/1144 [==============================] - 177s 154ms/step - loss: 0.0192 - val_loss: 0.0157

Epoch 00004: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 5/10
1144/1144 [==============================] - 111s 97ms/step - loss: 0.0186 - val_loss: 0.0156

Epoch 00005: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 6/10
1144/1144 [==============================] - 190s 166ms/step - loss: 0.0183 - val_loss: 0.0156

Epoch 00006: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 7/10
1144/1144 [==============================] - 200s 174ms/step - loss: 0.0180 - val_loss: 0.0150

Epoch 00007: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 8/10
1144/1144 [==============================] - 196s 171ms/step - loss: 0.0176 - val_loss: 0.0152

Epoch 00008: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 9/10
1144/1144 [==============================] - 193s 168ms/step - loss: 0.0175 - val_loss: 0.0151

Epoch 00009: saving model to .//checkpoints-8-4-1-0001-01-01 00:00:00-42/model.ckpt
Epoch 00009: early stopping
dict_keys(['loss', 'val_loss'])
